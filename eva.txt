import torch
from torch.utils.data import DataLoader, Dataset
import pandas as pd
import pickle
import numpy as np

class NeuMF(torch.nn.Module):
    def __init__(self, config, num_users, num_items):
        super(NeuMF, self).__init__()

        self.num_users = num_users
        self.num_items = num_items
        self.config = config
        
        # Phần ma trận phân tách (MF)
        self.embedding_user_mf = torch.nn.Embedding(num_embeddings=self.num_users, embedding_dim=config['latent_dim_mf'])
        self.embedding_item_mf = torch.nn.Embedding(num_embeddings=self.num_items, embedding_dim=config['latent_dim_mf'])
        
        # Phần MLP
        self.embedding_user_mlp = torch.nn.Embedding(num_embeddings=self.num_users, embedding_dim=config['latent_dim_mlp'])
        self.embedding_item_mlp = torch.nn.Embedding(num_embeddings=self.num_items, embedding_dim=config['latent_dim_mlp'])
        
        self.fc_layers = torch.nn.ModuleList()
        input_size = config['latent_dim_mlp'] * 2  # Kích thước đầu vào cho lớp đầu tiên (user + item embeddings)
        
        for out_size in config['layers']:
            self.fc_layers.append(torch.nn.Linear(input_size, out_size))
            input_size = out_size  # Cập nhật kích thước đầu vào cho lớp tiếp theo

        self.logits = torch.nn.Linear(in_features=config['layers'][-1] + config['latent_dim_mf'], out_features=1)
        self.sigmoid = torch.nn.Sigmoid()

    def forward(self, user_indices, item_indices):
        user_embedding_mlp = self.embedding_user_mlp(user_indices)
        item_embedding_mlp = self.embedding_item_mlp(item_indices)
        user_embedding_mf = self.embedding_user_mf(user_indices)
        item_embedding_mf = self.embedding_item_mf(item_indices)

        # Phần MF
        mf_vector = torch.mul(user_embedding_mf, item_embedding_mf)
        mf_vector = torch.nn.Dropout(self.config['dropout_rate_mf'])(mf_vector)

        # Phần MLP        
        mlp_vector = torch.cat([user_embedding_mlp, item_embedding_mlp], dim=-1)

        for layer in self.fc_layers:
            mlp_vector = layer(mlp_vector)
            mlp_vector = torch.nn.ReLU()(mlp_vector)
        
        mlp_vector = torch.nn.Dropout(self.config['dropout_rate_mlp'])(mlp_vector)

        vector = torch.cat([mlp_vector, mf_vector], dim=-1)
        logits = self.logits(vector)
        output = self.sigmoid(logits)
        return output


class RecommendationDataset(Dataset):
    def __init__(self, dataframe):
        self.users = torch.tensor(dataframe['user_id'].values)
        self.items = torch.tensor(dataframe['item_id'].values)
        self.labels = torch.tensor(dataframe['rating'].values)

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, index):
        return self.users[index], self.items[index], self.labels[index]

with open('model.pkl', 'rb') as file:
    model = pickle.load(file)

def calculate_hr_ndcg(model, dataloader, k=10):
    model.eval()
    hr = 0
    ndcg = 0
    total_users = 0

    for user_indices, item_indices, labels in dataloader:
        with torch.no_grad():
            outputs = model(user_indices, item_indices).squeeze()  # Dự đoán xác suất

        # Chuyển đổi dự đoán thành numpy array
        outputs_np = outputs.numpy()

        # Lấy các chỉ số của các item để xếp hạng
        item_indices_np = item_indices.numpy()
        labels_np = labels.numpy()

        # Tạo một dictionary để lưu trữ các dự đoán theo user
        user_item_scores = {}
        for user_id, item_id, score in zip(user_indices.numpy(), item_indices_np, outputs_np):
            if user_id not in user_item_scores:
                user_item_scores[user_id] = []
            user_item_scores[user_id].append((item_id, score))

        # Tính HR và NDCG cho từng user
        for user_id, item_scores in user_item_scores.items():
            # Sắp xếp theo score giảm dần
            item_scores.sort(key=lambda x: x[1], reverse=True)
            top_k_items = [item[0] for item in item_scores[:k]]
            relevant_items = np.where(labels_np == 1)[0]  # Các item có nhãn 1 (positive)

            # Tính HR
            if any(item in top_k_items for item in relevant_items):
                hr += 1
            
            # Tính NDCG
            dcg = sum((1 / np.log2(i + 2) for i, item in enumerate(top_k_items) if item in relevant_items))
            idcg = sum((1 / np.log2(i + 2) for i in range(min(k, len(relevant_items)))))
            ndcg += dcg / idcg if idcg > 0 else 0

            total_users += 1

    hr = hr / total_users if total_users > 0 else 0
    ndcg = ndcg / total_users if total_users > 0 else 0

    return hr, ndcg

# Sử dụng hàm để tính HR và NDCG
file_path = 'E:\\temp\\ml-100k\\u.data'
column_names = ['user_id', 'item_id', 'rating', 'timestamp']
df = pd.read_csv(file_path, sep='\t', header=None, names=column_names)
dataset = RecommendationDataset(df)
dataloader = DataLoader(dataset, batch_size=64, shuffle=True)

hr, ndcg = calculate_hr_ndcg(model, dataloader)
print(f'Hit Rate (HR@10): {hr:.4f}, NDCG@10: {ndcg:.4f}')